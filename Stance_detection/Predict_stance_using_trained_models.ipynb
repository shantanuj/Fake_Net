{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "import json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#directories\n",
    "\n",
    "input_csv = \"data_stance/combined_test_stance.csv\" #of format headline, body\n",
    "tfidf_vectorizer_articles_dir = 'best_stance_model_parameters/articles_tfidf_vectorizer.pk'\n",
    "tfidf_vectorizer_headlines_dir = 'best_stance_model_parameters/headline_tfidf_vectorizer.pk'\n",
    "tfidf_dims_file = 'best_stance_model_parameters/tf_idf_dims.txt'\n",
    "final_dl_model_h5 = 'best_stance_model_parameters/final_tfidf_bilstm.h5'\n",
    "final_dl_model_json = 'best_stance_model_parameters/final_tfidf_bilstm.json'\n",
    "vocab_dir = \"vocab.json\"\n",
    "max_head_length = 30 #assumption max headline will be 30 words\n",
    "max_article_length = 200 #HAVE TO STORE AS a txt later\n",
    "#word_vectors_dir = \"../word_vectors/corpus_relevant_vectors.txt\" #already stored by keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab with 155776 tokens \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading tfidf vectorizer and word vocab\"\"\"\n",
    "with open(tfidf_vectorizer_articles_dir, 'r') as fin:\n",
    "    tfidf_vectorizer_headlines = pickle.load(fin)\n",
    "    \n",
    "with open(tfidf_vectorizer_headlines_dir,'r') as fin:\n",
    "    tfidf_vectorizer_articles = pickle.load(fin)\n",
    "    \n",
    "with open(tfidf_dims_file,'r') as fin:\n",
    "    tfidf_dims = int(fin.read())\n",
    "\n",
    "def load_word_vocab(path=\"vocab.json\"):\n",
    "    with open(path, 'r') as fp:\n",
    "        word_to_int = json.load(fp)\n",
    "        int_to_word = {i:word for word,i in word_to_int.items()}\n",
    "    return word_to_int, int_to_word\n",
    "\n",
    "word_to_int, int_to_word = load_word_vocab(vocab_dir)\n",
    "word_to_int['<UNK>'] = len(word_to_int)\n",
    "int_to_word[len(int_to_word)] = \"<UNK>\"\n",
    "word_tokens_in_corpus = word_to_int.keys()\n",
    "\n",
    "print(\"Loaded vocab with {} tokens \".format(len(word_tokens_in_corpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully loaded model\n"
     ]
    }
   ],
   "source": [
    "'''Loading trained model for prediction'''\n",
    "json_file = open(final_dl_model_json,'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "stance_model = model_from_json(loaded_model_json)\n",
    "stance_model.load_weights(final_dl_model_h5)\n",
    "print(\"Succesfully loaded model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Text processing functions'''\n",
    "def tokenize_text(q, lower= True):\n",
    "    #Obtain word tokens \n",
    "    try:\n",
    "        tokens = word_tokenize(q.decode('utf-8'))\n",
    "    #except UnicodeDecodeError:\n",
    "     #   tokens = word_tokenize(q.decode('utf-8'))\n",
    "    except:\n",
    "        tokens = [\"<UNK>\"]\n",
    "    #print(q)\n",
    "    word_tokens = [word for word in tokens if word.isalpha()]  #only include words; not sure if best option\n",
    "    word_tokens = [word for word in word_tokens if word not in stop_words]\n",
    "    if(lower):\n",
    "        word_tokens = map(lambda x: x.lower(), word_tokens) #converting all to lower case\n",
    "    return word_tokens\n",
    "\n",
    "\n",
    "seq_length_list = []\n",
    "\n",
    "def get_word_to_int_sequence(tokens):\n",
    "    '''Returns sequence and updates vocab'''\n",
    "    '''Does increasing number of functions impact performance?'''\n",
    "    seq = []\n",
    "    #global max_seq_length\n",
    "    for token in tokens:\n",
    "        if(token not in word_to_int):\n",
    "            word_to_int[token] = len(word_to_int)\n",
    "            int_to_word[len(word_to_int)] = token\n",
    "            seq.append(word_to_int[token])\n",
    "        else:\n",
    "            seq.append(word_to_int[token])\n",
    "    #if(len(seq)>max_seq_length):\n",
    "     #   max_seq_length = len(seq)\n",
    "    seq_length_list.append(len(seq))\n",
    "    return seq\n",
    "\n",
    "def get_predictions_metrics(predictions, test_labels):\n",
    "    predicted_labels = map(lambda x: np.argmax(x), predictions)\n",
    "    ground_truth_labels = map(lambda x: np.argmax(x), test_labels)\n",
    "    accuracy = metrics.accuracy_score(predicted_labels, ground_truth_labels)\n",
    "    precision = metrics.precision_score(predicted_labels, ground_truth_labels, average = 'micro')\n",
    "    recall = metrics.recall_score(predicted_labels, ground_truth_labels, average = 'micro')\n",
    "    f1 = metrics.f1_score(predicted_labels, ground_truth_labels, average = 'micro')\n",
    "    conf_matrix = metrics.confusion_matrix(predicted_labels, ground_truth_labels)\n",
    "    return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "label_map = {'agree':0,'disagree':1, 'discuss':2, 'unrelated':3}\n",
    "inverse_label_map = {num:string for string,num in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stance(headlines, bodies):\n",
    "    \"\"\"Generate tfidf vectors for inputs\"\"\"\n",
    "    headlines_tfidf_vec = tfidf_vectorizer_headlines.transform(headlines).todense()\n",
    "    articles_tfidf_vec = tfidf_vectorizer_articles.transform(bodies).todense()\n",
    "    concatenated_tfidf_vec = np.concatenate((headlines_tfidf_vec, articles_tfidf_vec), axis =-1)\n",
    "    assert concatenated_tfidf_vec.shape[-1] == tfidf_dims\n",
    "    \"\"\"Create headline and article sequences\"\"\"\n",
    "    headline_sequences = map(lambda x: get_word_to_int_sequence(tokenize_text(x)),headlines) #converts each sentence to sequence of words\n",
    "    article_sequences =  map(lambda x: get_word_to_int_sequence(tokenize_text(x)),bodies)\n",
    "\n",
    "    headline_sequences = pad_sequences(headline_sequences, maxlen = max_head_length)\n",
    "    article_sequences = pad_sequences(article_sequences, maxlen = max_article_length)\n",
    "    '''Use model to predict'''\n",
    "    predictions = stance_model.predict([headline_sequences, article_sequences, concatenated_tfidf_vec], batch_size = 128)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    return predictions, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stance for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read in input csv for which predictions are required'''\n",
    "#input_structure = [[\"Headline1\",\"Headline2\"],[\"Body1\",\"Body2\"]] #this is a list containing \n",
    "\n",
    "\n",
    "\n",
    "name=\"test_set\" #name for output\n",
    "df_input_csv = pd.read_csv(input_csv)\n",
    "headlines = df_input_csv['Headline'].tolist()\n",
    "bodies = df_input_csv['Body'].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_dist, predicted_labels = get_stance(headlines, bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs written to: test_set_output_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "'''Write output predictions'''\n",
    "with open('{}_output_predictions.csv'.format(name),'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow([\"Headline\",\"Body\",\"Agree\",\"Disagree\",\"Discuss\",\"Unrelated\",\"Classification\"])\n",
    "    for i in range(len(predicted_labels)):\n",
    "        output_line = [headlines[i], bodies[i], prediction_dist[i][0], prediction_dist[i][1], prediction_dist[i][2], prediction_dist[i][3], inverse_label_map[predicted_labels[i]]]\n",
    "        writer.writerow(output_line)\n",
    "print(\"Outputs written to: {}\".format('{}_output_predictions.csv'.format(name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stance for kaggle subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"kaggle_first_1000\"\n",
    "input_csv = \"../final_combined_kaggle_scraped_pruned.csv\"\n",
    "df_input_csv = pd.read_csv(input_csv)\n",
    "headlines = df_input_csv['title'].tolist()[:1000]\n",
    "bodies = df_input_csv['text'].tolist()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_dist, predicted_labels = get_stance(headlines, bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs written to: kaggle_first_1000_output_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "'''Write output predictions'''\n",
    "with open('{}_output_predictions.csv'.format(name),'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow([\"Headline\",\"Body\",\"Agree\",\"Disagree\",\"Discuss\",\"Unrelated\",\"Classification\"])\n",
    "    for i in range(len(predicted_labels)):\n",
    "        output_line = [headlines[i], bodies[i], prediction_dist[i][0], prediction_dist[i][1], prediction_dist[i][2], prediction_dist[i][3], inverse_label_map[predicted_labels[i]]]\n",
    "        writer.writerow(output_line)\n",
    "print(\"Outputs written to: {}\".format('{}_output_predictions.csv'.format(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(predicted_labels==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use model to predict\n",
    "predictions = stance_model.predict([headline_sequences, article_sequences, concatenated_tfidf_vec], batch_size = 128)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "#predicted_labels = \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "body = \"The name Barack Obama infuriates President Trump. I believe he hates Obama more than he hates crooked Hillary, mainly because Obama was a successful and very popular president. So it was no surprise when one of the first things Trump wanted to do after taking office is tear apart Obamacare. If it had simply been called Health Care for Everyone or something like that, Trump might not have noticed. But it had Obama's name on it, and Trump couldn't tolerate that. So he wanted it torn down. So far, his efforts have totally failed, but that's nothing new. Next, Trump wants to erase all the good Obama did with easing U.S.-Cuba relations. The embargo is still in place. And yes, human rights violations are still taking place all the time in Cuba. But people are traveling there. It has been opened up to trade and to some news agencies. It is a relationship that will help the Cuban people in the long run. And it gives Americans a chance to see a nearby country that has been a mystery for decades.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
